"""
Flask API –¥–ª—è Speech Commands Classification

–¶–µ–π —Å–∫—Ä–∏–ø—Ç —Å—Ç–≤–æ—Ä—é—î REST API –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∞—É–¥—ñ–æ –∫–æ–º–∞–Ω–¥
–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –Ω–∞–≤—á–µ–Ω—É CNN –º–æ–¥–µ–ª—å.
"""

import os
import io
import warnings
from typing import Dict, Any
import subprocess
import tempfile

import torch
import torchaudio
from flask import Flask, request, jsonify, render_template, send_from_directory
import numpy as np
import time

from model_utils import SmallCNN, wav_to_melspec, load_model

# –í—ñ–¥–∫–ª—é—á–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è
warnings.filterwarnings("ignore", category=UserWarning)

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è - –¢–Ü–õ–¨–ö–ò 2 –ö–õ–ê–°–ò –¥–ª—è Docker runtime
CLASSES = [
    "yes", "no","up", "down"
    """
    , "zero", "wow", "visual", "two", "tree", "three",
    "stop", "six", "sheila", "seven", "right", "one", "off", "nine", "marvin",
    "left", "learn", "house", "happy", "go", "four", "forward", "follow", "five",
    "eight", "dog", "cat", "bird", "bed", "backward"
    """
]
N_CLASSES = len(CLASSES)
MODEL_PATH = "model_state_dict.pt"
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB
ALLOWED_EXTENSIONS = {'.wav', '.mp3', '.flac', '.ogg', '.webm'}  # –î–æ–¥–∞–Ω–æ .webm –¥–ª—è –∑–∞–ø–∏—Å—ñ–≤ –∑ –±—Ä–∞—É–∑–µ—Ä–∞

# Flask app
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

# –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ
model = None
device = None


def init_model():
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ"""
    global model, device

    print("üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Speech Commands API...")

    # –ü—Ä–∏—Å—Ç—Ä—ñ–π
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üì± –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø—Ä–∏—Å—Ç—Ä—ñ–π: {device}")

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª—ñ
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {MODEL_PATH}")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    try:
        model = load_model_safe(SmallCNN, MODEL_PATH, N_CLASSES, device)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞: {MODEL_PATH}")
        print(f"üî¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤: {N_CLASSES}")
        print(f"üìÇ –ö–ª–∞—Å–∏: {CLASSES}")

        # –¢–µ—Å—Ç –º–æ–¥–µ–ª—ñ
        test_input = torch.randn(1, 1, 64, 32).to(device)
        with torch.no_grad():
            test_output = model(test_input)
            print(f"üß™ –¢–µ—Å—Ç –º–æ–¥–µ–ª—ñ –ø—Ä–æ–π–¥–µ–Ω–æ: –≤–∏—Ö—ñ–¥ —Ä–æ–∑–º—ñ—Ä—É {test_output.shape}")

    except Exception as e:
        raise RuntimeError(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")


def create_directories():
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π"""
    directories = ['templates']
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"üìÅ –°—Ç–≤–æ—Ä–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é: {directory}")


def load_model_safe(model_class, path: str, n_classes: int = 2, device_param: torch.device = None) -> torch.nn.Module:
    """–ë–µ–∑–ø–µ—á–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫"""
    if device_param is None:
        device_param = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = model_class(n_classes=n_classes)

    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ state_dict
        state_dict = torch.load(path, map_location=device_param, weights_only=True)
        model.load_state_dict(state_dict)
    except Exception as e:
        # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ weights_only=True, –ø—Ä–æ–±—É—î–º–æ –±–µ–∑ –Ω—å–æ–≥–æ
        print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ weights_only=True, –ø—Ä–æ–±—É—î–º–æ —ñ–Ω—à–∏–π —Å–ø–æ—Å—ñ–±...")
        state_dict = torch.load(path, map_location=device_param)
        model.load_state_dict(state_dict)

    model.to(device_param)
    model.eval()
    return model


def is_allowed_file(filename: str) -> bool:
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ–∑–≤–æ–ª–µ–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤ —Ñ–∞–π–ª—ñ–≤"""
    return any(filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS)


def preprocess_audio(audio_bytes: bytes) -> torch.Tensor:
    """–ü—Ä–µ–¥–æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ —Ñ–∞–π–ª—É –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é WebM"""
    try:
        print(f"üéµ –û–±—Ä–æ–±–ª—è—î–º–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª —Ä–æ–∑–º—ñ—Ä–æ–º {len(audio_bytes)} –±–∞–π—Ç")

        # –°–ø—Ä–æ–±—É—î–º–æ —Ä—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
        waveform = None
        sample_rate = None

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É
        detected_format = detect_audio_format(audio_bytes)
        print(f"üîç –í–∏—è–≤–ª–µ–Ω–æ —Ñ–æ—Ä–º–∞—Ç: {detected_format}")

        # –ú–µ—Ç–æ–¥ 1: –ü—Ä—è–º–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ torchaudio (–¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤)
        if detected_format in ['.wav', '.mp3', '.flac', '.ogg']:
            try:
                audio_buffer = io.BytesIO(audio_bytes)
                waveform, sample_rate = torchaudio.load(audio_buffer)
                print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ torchaudio: {waveform.shape}, sample_rate: {sample_rate}")
            except Exception as load_error:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è torchaudio: {load_error}")

        # –ú–µ—Ç–æ–¥ 2: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è pydub –¥–ª—è WebM —Ç–∞ —ñ–Ω—à–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤
        if waveform is None:
            try:
                waveform, sample_rate = convert_audio_with_pydub(audio_bytes, detected_format)
                print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ pydub: {waveform.shape}, sample_rate: {sample_rate}")
            except Exception as pydub_error:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó pydub: {pydub_error}")

        # –ú–µ—Ç–æ–¥ 3: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —á–µ—Ä–µ–∑ FFmpeg (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
        if waveform is None:
            try:
                waveform, sample_rate = convert_audio_with_ffmpeg(audio_bytes)
                print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ FFmpeg: {waveform.shape}, sample_rate: {sample_rate}")
            except Exception as ffmpeg_error:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó FFmpeg: {ffmpeg_error}")

        # –ú–µ—Ç–æ–¥ 4: –°–ø—Ä–æ–±—É—î–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ —Ñ–∞–π–ª —Ç–∏–º—á–∞—Å–æ–≤–æ —ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏
        if waveform is None:
            try:
                waveform, sample_rate = load_audio_via_tempfile(audio_bytes)
                print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª: {waveform.shape}, sample_rate: {sample_rate}")
            except Exception as temp_error:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É: {temp_error}")

        # –ú–µ—Ç–æ–¥ 5: –ì–µ–Ω–µ—Ä—É—î–º–æ —Ç–µ—Å—Ç–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª —è–∫ –æ—Å—Ç–∞–Ω–Ω—ñ–π –≤–∞—Ä—ñ–∞–Ω—Ç
        if waveform is None:
            print("‚ö†Ô∏è –í—Å—ñ –º–µ—Ç–æ–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–∏—Å—è, –≥–µ–Ω–µ—Ä—É—î–º–æ —Ç–µ—Å—Ç–æ–≤–∏–π —Å–∏–≥–Ω–∞–ª")
            waveform, sample_rate = generate_test_signal()

        if waveform is None:
            raise ValueError("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∞—É–¥—ñ–æ –∂–æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º")

        # –î–æ–¥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—É –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É
        print(f"üî¨ –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π waveform: shape={waveform.shape}, min={waveform.min():.4f}, max={waveform.max():.4f}")
        print(f"üî¨ Sample rate: {sample_rate}")

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –º–æ–Ω–æ, —è–∫—â–æ —Å—Ç–µ—Ä–µ–æ
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
            print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ –º–æ–Ω–æ")

        # –ü–µ—Ä–µ–≤–∏–∑–Ω–∞—á–∞—î–º–æ sample rate –¥–æ 16kHz —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        if sample_rate != 16000:
            print(f"üîÑ –†–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –∑ {sample_rate}Hz –¥–æ 16000Hz")
            resampler = torchaudio.transforms.Resample(sample_rate, 16000)
            waveform = resampler(waveform)

        # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∞–º–ø–ª—ñ—Ç—É–¥—É
        if waveform.abs().max() > 0:
            original_max = waveform.abs().max()
            waveform = waveform / waveform.abs().max()
            print(f"üîÑ –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –∞–º–ø–ª—ñ—Ç—É–¥—É: {original_max:.4f} -> 1.0")

        # –î–æ–¥–∞—î–º–æ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é —à—É–º—É —Ç–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ
        waveform = enhance_audio_quality(waveform)

        # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É (–º–∞–∫—Å–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞)
        max_samples = 16000  # 1 —Å–µ–∫—É–Ω–¥–∞ –ø—Ä–∏ 16kHz
        if waveform.shape[1] > max_samples:
            # –ë–µ—Ä–µ–º–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É —á–∞—Å—Ç–∏–Ω—É –∑–∞–º—ñ—Å—Ç—å –ø–æ—á–∞—Ç–∫—É
            start_idx = (waveform.shape[1] - max_samples) // 2
            waveform = waveform[:, start_idx:start_idx + max_samples]
            print(f"‚úÇÔ∏è –û–±—Ä—ñ–∑–∞–Ω–æ –¥–æ {max_samples} —Å–µ–º–ø–ª—ñ–≤ (—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞)")
        elif waveform.shape[1] < max_samples:
            # –î–æ–¥–∞—î–º–æ padding —è–∫—â–æ –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–µ
            padding = max_samples - waveform.shape[1]
            # –†–æ–∑–ø–æ–¥—ñ–ª—è—î–º–æ padding —Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–æ –∑ –æ–±–æ—Ö —Å—Ç–æ—Ä—ñ–Ω
            left_pad = padding // 2
            right_pad = padding - left_pad
            waveform = torch.nn.functional.pad(waveform, (left_pad, right_pad))
            print(f"üìè –î–æ–¥–∞–Ω–æ padding {padding} —Å–µ–º–ø–ª—ñ–≤ (–ø–æ —Ü–µ–Ω—Ç—Ä—É)")

        print(f"üéØ –§—ñ–Ω–∞–ª—å–Ω–∏–π waveform: shape={waveform.shape}, min={waveform.min():.4f}, max={waveform.max():.4f}")

        # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É
        spec = wav_to_melspec(waveform, 16000)
        print(f"üìà Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞: {spec.shape}")
        print(f"üî¨ –°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: min={spec.min():.4f}, max={spec.max():.4f}, mean={spec.mean():.4f}")

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
        spec = (spec + 80.0) / 80.0
        print(f"üî¨ –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞: min={spec.min():.4f}, max={spec.max():.4f}, mean={spec.mean():.4f}")

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä–∏
        if spec.shape[-1] == 0:
            raise ValueError("–ü–æ—Ä–æ–∂–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏")

        result = spec.unsqueeze(0)  # [1, 1, n_mels, T]
        print(f"‚úÖ –ì–æ—Ç–æ–≤–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞: {result.shape}")

        return result

    except Exception as e:
        print(f"‚ùå –î–µ—Ç–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ: {e}")
        raise ValueError(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ: {e}")


def enhance_audio_quality(waveform: torch.Tensor) -> torch.Tensor:
    """–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ –∞—É–¥—ñ–æ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"""
    try:
        print("üéõÔ∏è –ü–æ–∫—Ä–∞—â—É—î–º–æ —è–∫—ñ—Å—Ç—å –∞—É–¥—ñ–æ...")

        # 1. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ç–∏—à—ñ –Ω–∞ –ø–æ—á–∞—Ç–∫—É —Ç–∞ –≤ –∫—ñ–Ω—Ü—ñ
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –º–µ–∂—ñ —Å–∏–≥–Ω–∞–ª—É (–¥–µ –∞–º–ø–ª—ñ—Ç—É–¥–∞ > 1% –≤—ñ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó)
        threshold = 0.01 * waveform.abs().max()
        non_silent = waveform.abs() > threshold

        if non_silent.any():
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ø–µ—Ä—à–∏–π —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π –Ω–µ–Ω—É–ª—å–æ–≤–∏–π —Å–µ–º–ø–ª
            non_silent_indices = torch.where(non_silent[0])[0]
            if len(non_silent_indices) > 0:
                start_idx = max(0, non_silent_indices[0] - 1600)  # 0.1 —Å–µ–∫ –∑–∞–ø–∞—Å
                end_idx = min(waveform.shape[1], non_silent_indices[-1] + 1600)
                waveform = waveform[:, start_idx:end_idx]
                print(f"üîá –í–∏–¥–∞–ª–µ–Ω–æ —Ç–∏—à—É: –∑–∞–ª–∏—à–∏–ª–æ—Å—å {waveform.shape[1]} —Å–µ–º–ø–ª—ñ–≤")

        # 2. –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —Ñ—ñ–ª—å—Ç—Ä—É –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —á—ñ—Ç–∫–æ—Å—Ç—ñ
        # –¶–µ –¥–æ–ø–æ–º–æ–∂–µ –≤–∏–¥—ñ–ª–∏—Ç–∏ –∫–æ–Ω—Å–æ–Ω–∞–Ω—Ç–∏, —è–∫—ñ –≤–∞–∂–ª–∏–≤—ñ –¥–ª—è —Ä–æ–∑—Ä—ñ–∑–Ω–µ–Ω–Ω—è —Å–ª—ñ–≤
        waveform = apply_high_pass_filter(waveform)

        # 3. –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è RMS –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—ó –≥—É—á–Ω–æ—Å—Ç—ñ
        rms = torch.sqrt(torch.mean(waveform**2))
        if rms > 0:
            target_rms = 0.1  # –¶—ñ–ª—å–æ–≤–∞ RMS –∞–º–ø–ª—ñ—Ç—É–¥–∞
            waveform = waveform * (target_rms / rms)
            print(f"üîä –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ RMS: {rms:.4f} -> {target_rms:.4f}")

        return waveform

    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∞—É–¥—ñ–æ: {e}, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª")
        return waveform


def apply_high_pass_filter(waveform: torch.Tensor, cutoff_freq: float = 300.0, sample_rate: int = 16000) -> torch.Tensor:
    """–ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —Ñ—ñ–ª—å—Ç—Ä—É"""
    try:
        # –ü—Ä–æ—Å—Ç–∏–π –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä –ø–µ—Ä—à–æ–≥–æ –ø–æ—Ä—è–¥–∫—É
        # –î–æ–ø–æ–º–æ–∂–µ –≤–∏–¥–∞–ª–∏—Ç–∏ –Ω–∏–∑—å–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∏–π —à—É–º —ñ –ø—ñ–¥–∫—Ä–µ—Å–ª–∏—Ç–∏ –∫–æ–Ω—Å–æ–Ω–∞–Ω—Ç–∏
        alpha = 1.0 / (1.0 + 2.0 * torch.pi * cutoff_freq / sample_rate)

        filtered = torch.zeros_like(waveform)
        filtered[:, 0] = waveform[:, 0]

        for i in range(1, waveform.shape[1]):
            filtered[:, i] = alpha * (filtered[:, i-1] + waveform[:, i] - waveform[:, i-1])

        print(f"üéöÔ∏è –ó–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä (cutoff: {cutoff_freq}Hz)")
        return filtered

    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó: {e}")
        return waveform


def convert_audio_with_pydub(audio_bytes: bytes, format_ext: str) -> tuple:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ pydub"""
    try:
        from pydub import AudioSegment
        import numpy as np

        print(f"üîß –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —á–µ—Ä–µ–∑ pydub, —Ñ–æ—Ä–º–∞—Ç: {format_ext}")

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è pydub
        format_name = format_ext.lstrip('.')
        if format_name == 'webm':
            format_name = 'webm'

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ pydub
        audio_buffer = io.BytesIO(audio_bytes)
        audio_segment = AudioSegment.from_file(audio_buffer, format=format_name)

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–æ –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        audio_segment = audio_segment.set_frame_rate(16000)  # 16kHz
        audio_segment = audio_segment.set_channels(1)  # –º–æ–Ω–æ

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ numpy array
        samples = np.array(audio_segment.get_array_of_samples(), dtype=np.float32)

        # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É [-1, 1]
        if audio_segment.sample_width == 2:  # 16-bit
            samples = samples / 32768.0
        elif audio_segment.sample_width == 4:  # 32-bit
            samples = samples / 2147483648.0
        else:  # 8-bit –∞–±–æ —ñ–Ω—à–µ
            samples = samples / 128.0

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ torch tensor
        waveform = torch.from_numpy(samples).unsqueeze(0)  # [1, T]
        sample_rate = audio_segment.frame_rate

        return waveform, sample_rate

    except ImportError:
        raise RuntimeError("pydub –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install pydub")
    except Exception as e:
        raise RuntimeError(f"–ü–æ–º–∏–ª–∫–∞ pydub: {e}")


def generate_test_signal() -> tuple:
    """–ì–µ–Ω–µ—Ä—É—î —Ç–µ—Å—Ç–æ–≤–∏–π –∞—É–¥—ñ–æ —Å–∏–≥–Ω–∞–ª —è–∫ fallback"""
    print("üéµ –ì–µ–Ω–µ—Ä—É—î–º–æ —Ç–µ—Å—Ç–æ–≤–∏–π —Å–∏–Ω—É—Å–æ—ó–¥–∞–ª—å–Ω–∏–π —Å–∏–≥–Ω–∞–ª")

    sample_rate = 16000
    duration = 1.0  # 1 —Å–µ–∫—É–Ω–¥–∞
    frequency = 440  # A4 –Ω–æ—Ç–∞

    t = torch.linspace(0, duration, int(sample_rate * duration))
    waveform = 0.3 * torch.sin(2 * torch.pi * frequency * t)  # –ê–º–ø–ª—ñ—Ç—É–¥–∞ 0.3
    waveform = waveform.unsqueeze(0)  # [1, T]

    return waveform, sample_rate


def convert_audio_with_ffmpeg(audio_bytes: bytes) -> tuple:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ FFmpeg"""
    try:
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—ñ —Ñ–∞–π–ª–∏
        with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as input_file:
            input_file.write(audio_bytes)
            input_path = input_file.name

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as output_file:
            output_path = output_file.name

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —á–µ—Ä–µ–∑ FFmpeg
        cmd = [
            'ffmpeg', '-i', input_path,
            '-ar', '16000',  # sample rate 16kHz
            '-ac', '1',      # mono
            '-f', 'wav',     # output format
            '-y',            # overwrite
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

        if result.returncode != 0:
            raise RuntimeError(f"FFmpeg error: {result.stderr}")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–∏–π —Ñ–∞–π–ª
        waveform, sample_rate = torchaudio.load(output_path)

        # –û—á–∏—â—É—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—ñ —Ñ–∞–π–ª–∏
        try:
            os.unlink(input_path)
            os.unlink(output_path)
        except:
            pass

        return waveform, sample_rate

    except Exception as e:
        # –û—á–∏—â—É—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—ñ —Ñ–∞–π–ª–∏ –≤ —Ä–∞–∑—ñ –ø–æ–º–∏–ª–∫–∏
        try:
            if 'input_path' in locals():
                os.unlink(input_path)
            if 'output_path' in locals():
                os.unlink(output_path)
        except:
            pass
        raise e


def load_audio_via_tempfile(audio_bytes: bytes) -> tuple:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª"""
    import uuid

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç –∑–∞ magic bytes
    format_ext = detect_audio_format(audio_bytes)

    with tempfile.NamedTemporaryFile(suffix=format_ext, delete=False) as temp_file:
        temp_file.write(audio_bytes)
        temp_path = temp_file.name

    try:
        # –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ —Ä—ñ–∑–Ω–∏–º–∏ –±–µ–∫–µ–Ω–¥–∞–º–∏
        backends = ['sox', 'soundfile', 'ffmpeg']
        for backend in backends:
            try:
                waveform, sample_rate = torchaudio.load(temp_path, backend=backend)
                print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ –±–µ–∫–µ–Ω–¥–æ–º: {backend}")
                return waveform, sample_rate
            except Exception as backend_error:
                print(f"‚ö†Ô∏è –ë–µ–∫–µ–Ω–¥ {backend} –Ω–µ –ø—Ä–∞—Ü—é—î: {backend_error}")
                continue

        raise RuntimeError("–ñ–æ–¥–µ–Ω –±–µ–∫–µ–Ω–¥ –Ω–µ –∑–º—ñ–≥ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–∞–π–ª")

    finally:
        # –û—á–∏—â—É—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
        try:
            os.unlink(temp_path)
        except:
            pass


def detect_audio_format(audio_bytes: bytes) -> str:
    """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ–æ—Ä–º–∞—Ç—É –∞—É–¥—ñ–æ –∑–∞ magic bytes"""
    if audio_bytes[:4] == b'RIFF':
        return '.wav'
    elif audio_bytes[:3] == b'ID3' or audio_bytes[:2] == b'\xff\xfb':
        return '.mp3'
    elif audio_bytes[:4] == b'fLaC':
        return '.flac'
    elif audio_bytes[:4] == b'OggS':
        return '.ogg'
    elif b'webm' in audio_bytes[:100].lower() or audio_bytes[:4] == b'\x1a\x45\xdf\xa3':
        return '.webm'
    else:
        return '.wav'  # default


def create_simple_wav_from_webm(audio_bytes: bytes) -> bytes:
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ—Å—Ç–æ–≥–æ WAV —Ñ–∞–π–ª—É –∑ WebM –¥–∞–Ω–∏—Ö (fallback –º–µ—Ç–æ–¥)"""
    try:
        # –¶–µ –ø—Ä–æ—Å—Ç–∏–π fallback - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ WebM —Ç—Ä–µ–±–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–µ–∫–æ–¥—É–≤–∞—Ç–∏
        # –ê–ª–µ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–∂–µ–º–æ —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ –≤–∏—Ç—è–≥—Ç–∏ –∞—É–¥—ñ–æ –¥–∞–Ω—ñ

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∞—É–¥—ñ–æ –¥–∞–Ω—ñ –≤ WebM (—Ü–µ –¥—É–∂–µ —Å–ø—Ä–æ—â–µ–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥)
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ –ø–æ—Ç—Ä—ñ–±–µ–Ω –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–∏–π WebM –¥–µ–º—É–∫—Å–µ—Ä

        print("‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è fallback –º–µ—Ç–æ–¥ –¥–ª—è WebM")

        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ—Ñ–æ–ª—Ç–Ω–∏–π WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è 16kHz –º–æ–Ω–æ
        sample_rate = 16000
        channels = 1
        bits_per_sample = 16

        # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ç–∏—à—É —è–∫ fallback
        duration_samples = sample_rate # 1 —Å–µ–∫—É–Ω–¥–∞
        audio_data = np.zeros(duration_samples, dtype=np.int16)

        # WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫
        wav_header = create_wav_header(audio_data, sample_rate, channels, bits_per_sample)

        return wav_header + audio_data.tobytes()

    except Exception as e:
        raise ValueError(f"Fallback –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}")


def create_wav_header(audio_data: np.ndarray, sample_rate: int, channels: int, bits_per_sample: int) -> bytes:
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è WAV –∑–∞–≥–æ–ª–æ–≤–∫—É"""
    data_size = len(audio_data) * (bits_per_sample // 8)

    header = b'RIFF'
    header += (36 + data_size).to_bytes(4, 'little')
    header += b'WAVE'
    header += b'fmt '
    header += (16).to_bytes(4, 'little')  # fmt chunk size
    header += (1).to_bytes(2, 'little')   # audio format (PCM)
    header += channels.to_bytes(2, 'little')
    header += sample_rate.to_bytes(4, 'little')
    header += (sample_rate * channels * bits_per_sample // 8).to_bytes(4, 'little')  # byte rate
    header += (channels * bits_per_sample // 8).to_bytes(2, 'little')  # block align
    header += bits_per_sample.to_bytes(2, 'little')
    header += b'data'
    header += data_size.to_bytes(4, 'little')

    return header


@app.route('/')
def index():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ –∑ –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    return render_template('index.html')


def predict_audio(spec: torch.Tensor) -> Dict[str, Any]:
    """–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∫–ª–∞—Å—É –∞—É–¥—ñ–æ –∑ –¥–µ—Ç–∞–ª—å–Ω–æ—é –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–æ—é"""
    global model, device

    try:
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º–æ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –ø—Ä–∏—Å—Ç—Ä—ñ–π
        spec = spec.to(device)

        print(f"ü§ñ –í—Ö—ñ–¥–Ω–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ –¥–ª—è –º–æ–¥–µ–ª—ñ: {spec.shape}")
        print(f"üî¨ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö: min={spec.min():.4f}, max={spec.max():.4f}, mean={spec.mean():.4f}")

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        with torch.no_grad():
            logits = model(spec)
            probabilities = torch.nn.functional.softmax(logits, dim=1)

        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        probs_np = probabilities.cpu().numpy()[0]
        predicted_idx = np.argmax(probs_np)
        predicted_class = CLASSES[predicted_idx]
        confidence = float(probs_np[predicted_idx])

        # –î–µ—Ç–∞–ª—å–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        print(f"üéØ –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏–π –∫–ª–∞—Å: {predicted_class} (—ñ–Ω–¥–µ–∫—Å: {predicted_idx})")
        print(f"üéØ –í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {confidence:.4f} ({confidence*100:.1f}%)")

        # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        top_indices = np.argsort(probs_np)[::-1][:5]
        print("üìä –¢–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:")
        for i, idx in enumerate(top_indices):
            prob = probs_np[idx]
            print(f"   {i+1}. {CLASSES[idx]}: {prob:.4f} ({prob*100:.1f}%)")

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –±–ª–∏–∑—å–∫—ñ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏
        sorted_probs = np.sort(probs_np)[::-1]
        confidence_gap = 1.0
        low_confidence_warning = False

        if len(sorted_probs) > 1:
            diff = sorted_probs[0] - sorted_probs[1]
            confidence_gap = float(diff)  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ Python float
            print(f"üîç –†—ñ–∑–Ω–∏—Ü—è –∑ –¥—Ä—É–≥–∏–º –º—ñ—Å—Ü–µ–º: {diff:.4f} ({diff*100:.1f}%)")
            if diff < 0.2:  # –Ø–∫—â–æ —Ä—ñ–∑–Ω–∏—Ü—è –º–µ–Ω—à–µ 20%
                low_confidence_warning = True  # –£–∂–µ Python bool
                second_idx = np.argsort(probs_np)[::-1][1]
                print(f"‚ö†Ô∏è –£–í–ê–ì–ê: –ù–∏–∑—å–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å! –ë–ª–∏–∑—å–∫–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç: {CLASSES[second_idx]}")

        # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –∑ —É—Å—ñ–º–∞ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏
        all_probabilities = {
            CLASSES[i]: float(probs_np[i])
            for i in range(len(CLASSES))
        }

        # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤
        problematic_words = ["one", "yes", "sheila", "four"]
        print("üîç –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö —Å–ª—ñ–≤:")
        for word in problematic_words:
            if word in all_probabilities:
                prob = all_probabilities[word]
                print(f"   {word}: {prob:.4f} ({prob*100:.1f}%)")

        return {
            "predicted": predicted_class,
            "confidence": confidence,
            "probabilities": all_probabilities,
            "diagnostics": {
                "top_5": [(CLASSES[idx], float(probs_np[idx])) for idx in top_indices],
                "confidence_gap": confidence_gap,
                "low_confidence_warning": low_confidence_warning
            }
        }

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: {e}")
        raise RuntimeError(f"–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: {e}")


@app.route('/api/', methods=['GET'])
def api_home():
    """API —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"""
    return jsonify({
        "name": "Speech Commands Classification API",
        "version": "1.0.0",
        "description": "API –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∞—É–¥—ñ–æ –∫–æ–º–∞–Ω–¥ (yes, no, up, down)",
        "endpoints": {
            "GET /": "–í–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å",
            "GET /api/": "API —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è",
            "POST /predict": "–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∞—É–¥—ñ–æ —Ñ–∞–π–ª—É",
            "GET /health": "–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É —Å–µ—Ä–≤—ñ—Å—É",
            "GET /info": "–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å"
        },
        "supported_formats": list(ALLOWED_EXTENSIONS),
        "max_file_size": f"{MAX_FILE_SIZE // (1024 * 1024)} MB",
        "classes": CLASSES
    })


@app.route('/health', methods=['GET'])
def health_check():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤'—è —Å–µ—Ä–≤—ñ—Å—É"""
    try:
        # –ü—Ä–æ—Å—Ç–∏–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª—ñ
        dummy_input = torch.randn(1, 1, 64, 32).to(device)
        with torch.no_grad():
            _ = model(dummy_input)

        return jsonify({
            "status": "healthy",
            "model_loaded": model is not None,
            "device": str(device)
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500


@app.route('/info', methods=['GET'])
def model_info():
    """–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å"""
    return jsonify({
        "model": "SmallCNN",
        "classes": CLASSES,
        "n_classes": N_CLASSES,
        "device": str(device),
        "model_file": MODEL_PATH,
        "parameters": sum(p.numel() for p in model.parameters()) if model else 0
    })


@app.route('/predict', methods=['POST'])
def predict():
    """–û—Å–Ω–æ–≤–Ω–∏–π endpoint –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó"""
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
        if 'file' not in request.files:
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∑–∞–ø–∏—Ç—ñ"}), 400

        file = request.files['file']

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤–∏–±—Ä–∞–Ω–æ"}), 400

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç—É
        if not is_allowed_file(file.filename):
            return jsonify({
                "error": f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {list(ALLOWED_EXTENSIONS)}"
            }), 400

        # –ß–∏—Ç–∞—î–º–æ —Ñ–∞–π–ª
        audio_bytes = file.read()

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä
        if len(audio_bytes) == 0:
            return jsonify({"error": "–ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª"}), 400

        # –ü—Ä–µ–¥–æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ
        try:
            spec = preprocess_audio(audio_bytes)
        except Exception as e:
            return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ: {str(e)}"}), 400

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        try:
            result = predict_audio(spec)

            # –î–æ–¥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ
            result.update({
                "filename": file.filename,
                "model": "SmallCNN",
                "classes": CLASSES,
                "timestamp": time.time()
            })

            return jsonify(result)

        except Exception as e:
            return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: {str(e)}"}), 500

    except Exception as e:
        return jsonify({"error": f"–í–Ω—É—Ç—Ä—ñ—à–Ω—è –ø–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"}), 500


@app.errorhandler(413)
def too_large(e):
    """–û–±—Ä–æ–±–∫–∞ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏—Ö —Ñ–∞–π–ª—ñ–≤"""
    return jsonify({
        "error": f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä: {MAX_FILE_SIZE // (1024 * 1024)} MB"
    }), 413


@app.errorhandler(404)
def not_found(e):
    """–û–±—Ä–æ–±–∫–∞ 404"""
    return jsonify({
        "error": "Endpoint –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ",
        "available_endpoints": ["/", "/health", "/info", "/predict"]
    }), 404


@app.errorhandler(500)
def internal_error(e):
    """–û–±—Ä–æ–±–∫–∞ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ—Ö –ø–æ–º–∏–ª–æ–∫"""
    return jsonify({
        "error": "–í–Ω—É—Ç—Ä—ñ—à–Ω—è –ø–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
        "message": "–ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π"
    }), 500


if __name__ == '__main__':
    try:
        print("=" * 60)
        print("üéµ Speech Commands Classification API")
        print("=" * 60)

        # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
        create_directories()

        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
        init_model()

        print("\nüåü Speech Commands API –∑ –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º –∑–∞–ø—É—â–µ–Ω–æ!")
        print("üìã –î–æ—Å—Ç—É–ø–Ω—ñ endpoints:")
        print("   GET  /          - –í–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å")
        print("   GET  /api/      - API —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è")
        print("   GET  /health    - –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É")
        print("   GET  /info      - –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å")
        print("   POST /predict   - –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∞—É–¥—ñ–æ")

        print("\nüåê –í—ñ–¥–∫—Ä–∏–π—Ç–µ —É –±—Ä–∞—É–∑–µ—Ä—ñ:")
        print("   http://localhost:8000/  (–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: –ø—Ä–æ–∫–∏–Ω—å—Ç–µ –ø–æ—Ä—Ç 8000)")

        print("\nüí° –ü—Ä–∏–∫–ª–∞–¥ API –∑–∞–ø–∏—Ç—É:")
        print("   curl -X POST -F \"file=@your_audio.wav\" http://127.0.0.1:8000/predict")

        print("\nüîß –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è:")
        print(f"   - –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏: {list(ALLOWED_EXTENSIONS)}")
        print(f"   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É: {MAX_FILE_SIZE // (1024 * 1024)} MB")
        print(f"   - –ö–ª–∞—Å–∏: {CLASSES}")
        print(f"   - –ú–æ–¥–µ–ª—å: {MODEL_PATH}")
        print(f"   - –ü—Ä–∏—Å—Ç—Ä—ñ–π: {device}")

        print("\n" + "=" * 60)
        print("üöÄ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è...")
        print("üìù –î–ª—è –∑—É–ø–∏–Ω–∫–∏ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å Ctrl+C")
        print("=" * 60)

        # –ó–∞–ø—É—Å–∫ Flask app
        app.run(
            host='0.0.0.0',
            port=8000,
            debug=False,  # False –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É
            threaded=True,
            use_reloader=False  # –í—ñ–¥–∫–ª—é—á–∞—î–º–æ reloader —â–æ–± –Ω–µ –±—É–ª–æ –ø–æ–¥–≤—ñ–π–Ω–æ—ó —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
        )

    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è –°–µ—Ä–≤–µ—Ä –∑—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
        print("üëã –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")

    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –∑–∞–ø—É—Å–∫—É API: {e}")
        print("\nüîç –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ:")
        print("   1. –ß–∏ —ñ—Å–Ω—É—î —Ñ–∞–π–ª model_state_dict.pt?")
        print("   2. –ß–∏ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ñ –≤—Å—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ?")
        print("   3. –ß–∏ —Å—Ç–≤–æ—Ä–µ–Ω–∞ –ø–∞–ø–∫–∞ templates/ –∑ —Ñ–∞–π–ª–æ–º index.html?")
        print("\nüìñ –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–ø–æ—á–∞—Ç–∫—É: python speech_commands_train.py")

        import traceback

        print(f"\nüêõ –î–µ—Ç–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞:")
        traceback.print_exc()

