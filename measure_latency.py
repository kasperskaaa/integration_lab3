#!/usr/bin/env python3
"""
–í–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è latency —Ç–∞ —ñ–Ω—à–∏—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª—ñ
"""

import argparse
import json
import time
import csv
from pathlib import Path
import warnings

import torch
import numpy as np

from model_utils import SmallCNN, wav_to_melspec, load_model

warnings.filterwarnings("ignore", category=UserWarning)

# –ö–ª–∞—Å–∏ –º–æ–¥–µ–ª—ñ
CLASSES = [
    "yes", "no",
    "up", "down", "zero", "wow", "visual", "two", "tree", "three",
    "stop", "six", "sheila", "seven", "right", "one", "off", "nine", "marvin",
    "left", "learn", "house", "happy", "go", "four", "forward", "follow", "five",
    "eight", "dog", "cat", "bird", "bed", "backward"
]


def measure_comprehensive_metrics(model_path: str, num_iterations: int = 100):
    """
    –í–∏–º—ñ—Ä—é—î –∫–æ–º–ø–ª–µ–∫—Å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª—ñ
    """
    print("=" * 60)
    print("‚è±Ô∏è  –í–ò–ú–Ü–†–Æ–í–ê–ù–ù–Ø –ú–ï–¢–†–ò–ö –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü")
    print("=" * 60)

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    device = torch.device("cpu")
    model = load_model(SmallCNN, model_path, len(CLASSES), device)
    model.eval()

    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞: {model_path}")
    print(f"üîÑ –ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π: {num_iterations}")

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –≤—Ö–æ–¥—É
    torch.manual_seed(42)
    sample_rate = 16000
    duration = 1.0
    t = torch.linspace(0, duration, int(sample_rate * duration))
    waveform = torch.sin(2 * np.pi * 440.0 * t).unsqueeze(0)
    melspec = wav_to_melspec(waveform, sample_rate).unsqueeze(0).to(device)

    print(f"üìä –†–æ–∑–º—ñ—Ä –≤—Ö–æ–¥—É: {melspec.shape}")

    # Warm-up
    print("\nüî• Warm-up (10 —ñ—Ç–µ—Ä–∞—Ü—ñ–π)...")
    with torch.no_grad():
        for _ in range(10):
            _ = model(melspec)

    # –í–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è latency
    print("\n‚è±Ô∏è  –í–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è inference latency...")
    latencies = []

    with torch.no_grad():
        for i in range(num_iterations):
            start_time = time.perf_counter()
            output = model(melspec)
            end_time = time.perf_counter()

            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)

            if (i + 1) % 20 == 0:
                print(f"  –ü—Ä–æ–≥—Ä–µ—Å: {i + 1}/{num_iterations}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    latencies = np.array(latencies)

    metrics = {
        "model_path": model_path,
        "num_iterations": num_iterations,
        "device": str(device),
        "input_shape": list(melspec.shape),
        "latency_ms": {
            "mean": float(np.mean(latencies)),
            "median": float(np.median(latencies)),
            "std": float(np.std(latencies)),
            "min": float(np.min(latencies)),
            "max": float(np.max(latencies)),
            "p95": float(np.percentile(latencies, 95)),
            "p99": float(np.percentile(latencies, 99))
        },
        "throughput": {
            "requests_per_second": float(1000 / np.mean(latencies))
        },
        "model_info": {
            "total_parameters": sum(p.numel() for p in model.parameters()),
            "trainable_parameters": sum(p.numel() for p in model.parameters() if p.requires_grad)
        }
    }

    # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –í–ò–ú–Ü–†–Æ–í–ê–ù–¨")
    print("=" * 60)
    print(f"\n‚è±Ô∏è  Latency (–º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏):")
    print(f"  ‚Ä¢ –°–µ—Ä–µ–¥–Ω—î:     {metrics['latency_ms']['mean']:.3f} ms")
    print(f"  ‚Ä¢ –ú–µ–¥—ñ–∞–Ω–∞:     {metrics['latency_ms']['median']:.3f} ms")
    print(f"  ‚Ä¢ –ú—ñ–Ω:         {metrics['latency_ms']['min']:.3f} ms")
    print(f"  ‚Ä¢ –ú–∞–∫—Å:        {metrics['latency_ms']['max']:.3f} ms")
    print(f"  ‚Ä¢ Std:         {metrics['latency_ms']['std']:.3f} ms")
    print(f"  ‚Ä¢ P95:         {metrics['latency_ms']['p95']:.3f} ms")
    print(f"  ‚Ä¢ P99:         {metrics['latency_ms']['p99']:.3f} ms")

    print(f"\nüöÄ Throughput:")
    print(f"  ‚Ä¢ –ó–∞–ø–∏—Ç—ñ–≤/—Å–µ–∫: {metrics['throughput']['requests_per_second']:.2f}")

    print(f"\nüìà –ú–æ–¥–µ–ª—å:")
    print(f"  ‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤:  {metrics['model_info']['total_parameters']:,}")

    return metrics, latencies


def save_metrics(metrics: dict, latencies: np.ndarray, output_prefix: str):
    """–ó–±–µ—Ä—ñ–≥–∞—î –º–µ—Ç—Ä–∏–∫–∏ —É JSON —Ç–∞ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""

    # JSON
    json_path = f"{output_prefix}.json"
    with open(json_path, "w") as f:
        json.dump(metrics, f, indent=2)
    print(f"\n‚úÖ JSON –º–µ—Ç—Ä–∏–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {json_path}")

    # CSV –∑ –¥–µ—Ç–∞–ª—å–Ω–∏–º–∏ latency
    csv_path = f"{output_prefix}.csv"
    with open(csv_path, "w", newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["iteration", "latency_ms"])
        for i, latency in enumerate(latencies, 1):
            writer.writerow([i, latency])
    print(f"‚úÖ CSV –¥–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {csv_path}")

    # CSV –∑ –∞–≥—Ä–µ–≥–æ–≤–∞–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    summary_csv_path = f"{output_prefix}_summary.csv"
    with open(summary_csv_path, "w", newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["metric", "value", "unit"])
        writer.writerow(["mean_latency", metrics["latency_ms"]["mean"], "ms"])
        writer.writerow(["median_latency", metrics["latency_ms"]["median"], "ms"])
        writer.writerow(["std_latency", metrics["latency_ms"]["std"], "ms"])
        writer.writerow(["min_latency", metrics["latency_ms"]["min"], "ms"])
        writer.writerow(["max_latency", metrics["latency_ms"]["max"], "ms"])
        writer.writerow(["p95_latency", metrics["latency_ms"]["p95"], "ms"])
        writer.writerow(["p99_latency", metrics["latency_ms"]["p99"], "ms"])
        writer.writerow(["throughput", metrics["throughput"]["requests_per_second"], "req/s"])
        writer.writerow(["total_parameters", metrics["model_info"]["total_parameters"], "count"])
    print(f"‚úÖ –ê–≥—Ä–µ–≥–æ–≤–∞–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {summary_csv_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–í–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª—ñ")
    parser.add_argument("--model-path", type=str, required=True,
                        help="–®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ (.pt)")
    parser.add_argument("--output", type=str, default="latency_metrics",
                        help="–ü—Ä–µ—Ñ—ñ–∫—Å –¥–ª—è –≤–∏—Ö—ñ–¥–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤")
    parser.add_argument("--iterations", type=int, default=100,
                        help="–ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π –¥–ª—è –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è")

    args = parser.parse_args()

    metrics, latencies = measure_comprehensive_metrics(args.model_path, args.iterations)
    save_metrics(metrics, latencies, args.output)

    print("\n‚úÖ –í–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
