#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É –∑ —É—Å—ñ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ñ–≤ pipeline
"""

import argparse
import json
import os
from pathlib import Path
from datetime import datetime


def load_json_safe(filepath: str):
    """–ë–µ–∑–ø–µ—á–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è JSON"""
    try:
        with open(filepath, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ {filepath}: {e}")
        return None


def generate_report(artifacts_dir: str, output_file: str):
    """–ì–µ–Ω–µ—Ä—É—î –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏–π –∑–≤—ñ—Ç"""

    print("=" * 60)
    print("üìù –ì–ï–ù–ï–†–ê–¶–Ü–Ø –§–Ü–ù–ê–õ–¨–ù–û–ì–û –ó–í–Ü–¢–£")
    print("=" * 60)

    artifacts_path = Path(artifacts_dir)

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ñ–≤
    validation_data = None
    metrics_data = None

    # –®—É–∫–∞—î–º–æ validation report
    validation_json = artifacts_path / "validation-report" / "validation_report.json"
    if validation_json.exists():
        validation_data = load_json_safe(str(validation_json))
        print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –∑–≤—ñ—Ç –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")

    # –®—É–∫–∞—î–º–æ performance metrics
    metrics_json = artifacts_path / "performance-metrics" / "latency_metrics.json"
    if metrics_json.exists():
        metrics_data = load_json_safe(str(metrics_json))
        print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ")

    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è Markdown –∑–≤—ñ—Ç—É
    report = f"""# ü§ñ CI/CD Pipeline - –ó–≤—ñ—Ç –≤–∏–∫–æ–Ω–∞–Ω–Ω—è

**–î–∞—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## üìã –û–≥–ª—è–¥

–¶–µ–π –∑–≤—ñ—Ç –º—ñ—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ pipeline –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –¥–µ–ø–ª–æ—é –º–æ–¥–µ–ª—ñ Speech Commands Classification.

"""

    # –°–µ–∫—Ü—ñ—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    if validation_data:
        status_emoji = "‚úÖ" if validation_data.get("status") == "PASS" else "‚ùå"
        report += f"""## üîç –í–∞–ª—ñ–¥–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ {status_emoji}

### –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–µ—Å—Ç—É –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ

- **–°—Ç–∞—Ç—É—Å:** {validation_data.get('status', 'N/A')}
- **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å:** {'‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ' if validation_data.get('consistency_check') else '‚ùå –ù–µ –ø—Ä–æ–π–¥–µ–Ω–æ'}
- **–†–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ:** {validation_data.get('model_size_mb', 0):.2f} MB
- **–°–µ—Ä–µ–¥–Ω—è –¥–æ–≤—ñ—Ä–∞:** {validation_data.get('avg_confidence', 0):.4f}
- **–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –¥–æ–≤—ñ—Ä–∏:** {validation_data.get('std_confidence', 0):.6f}

### –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –∑—Ä–∞–∑–∫—É

"""
        for i, (pred, conf) in enumerate(zip(
            validation_data.get('predictions', []),
            validation_data.get('confidences', [])
        ), 1):
            report += f"{i}. **{pred}** - –¥–æ–≤—ñ—Ä–∞: {conf:.4f}\n"

        report += f"""
### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ

- **–í—Å—å–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤:** {validation_data.get('total_parameters', 0):,}
- **–¢—Ä–µ–Ω–æ–≤–∞–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤:** {validation_data.get('trainable_parameters', 0):,}

"""

    # –°–µ–∫—Ü—ñ—è –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
    if metrics_data:
        latency = metrics_data.get('latency_ms', {})
        throughput = metrics_data.get('throughput', {})

        report += f"""## ‚è±Ô∏è –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ

### Inference Latency

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–Ω—è |
|---------|----------|
| –°–µ—Ä–µ–¥–Ω—î | {latency.get('mean', 0):.3f} ms |
| –ú–µ–¥—ñ–∞–Ω–∞ | {latency.get('median', 0):.3f} ms |
| –ú—ñ–Ω—ñ–º—É–º | {latency.get('min', 0):.3f} ms |
| –ú–∞–∫—Å–∏–º—É–º | {latency.get('max', 0):.3f} ms |
| Std Dev | {latency.get('std', 0):.3f} ms |
| P95 | {latency.get('p95', 0):.3f} ms |
| P99 | {latency.get('p99', 0):.3f} ms |

### Throughput

- **–ó–∞–ø–∏—Ç—ñ–≤ –∑–∞ —Å–µ–∫—É–Ω–¥—É:** {throughput.get('requests_per_second', 0):.2f} req/s

### –î–µ—Ç–∞–ª—ñ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è

- **–ö—ñ–ª—å–∫—ñ—Å—Ç—å —ñ—Ç–µ—Ä–∞—Ü—ñ–π:** {metrics_data.get('num_iterations', 'N/A')}
- **–ü—Ä–∏—Å—Ç—Ä—ñ–π:** {metrics_data.get('device', 'N/A')}
- **–†–æ–∑–º—ñ—Ä –≤—Ö–æ–¥—É:** {metrics_data.get('input_shape', 'N/A')}

"""

    # –°–µ–∫—Ü—ñ—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ñ–≤
    report += """## üì¶ –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏

### –ú–æ–¥–µ–ª—å
- `model_state_dict.pt` - –Ω–∞–≤—á–µ–Ω–∞ –º–æ–¥–µ–ª—å (state dict)
- `model_scripted.pt` - TorchScript –º–æ–¥–µ–ª—å

### –ú–µ—Ç—Ä–∏–∫–∏
- `latency_metrics.json` - –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
- `latency_metrics.csv` - CSV –∑ latency –¥–∞–Ω–∏–º–∏
- `validation_report.json` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó

### Docker –æ–±—Ä–∞–∑–∏
- Inference image: `ghcr.io/<repository>:latest`
- –î–æ—Å—Ç—É–ø–Ω–æ –≤ GitHub Container Registry

"""

    # –°–µ–∫—Ü—ñ—è –≤–∏—Å–Ω–æ–≤–∫—ñ–≤
    report += """## üéØ –í–∏—Å–Ω–æ–≤–∫–∏

"""

    if validation_data and validation_data.get("status") == "PASS":
        report += "‚úÖ –ú–æ–¥–µ–ª—å –ø—Ä–æ–π—à–ª–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—é —É—Å–ø—ñ—à–Ω–æ\n"
    else:
        report += "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –ø—Ä–æ–π—à–ª–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—é\n"

    if metrics_data and latency.get('mean', 0) < 100:
        report += "‚úÖ Latency –≤ –¥–æ–ø—É—Å—Ç–∏–º–∏—Ö –º–µ–∂–∞—Ö (<100ms)\n"
    elif metrics_data:
        report += "‚ö†Ô∏è Latency –ø–µ—Ä–µ–≤–∏—â—É—î —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è\n"

    report += """
## üöÄ –ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏

1. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ –≤ GitHub Actions
2. –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Docker –æ–±—Ä–∞–∑ –∑ GHCR
3. –†–æ–∑–≥–æ—Ä–Ω—ñ—Ç—å —Å–µ—Ä–≤—ñ—Å —É production —Å–µ—Ä–µ–¥–æ–≤–∏—â—ñ

---

*–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ GitHub Actions CI/CD Pipeline*
"""

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\n‚úÖ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_file}")
    print("=" * 60)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É")
    parser.add_argument("--artifacts-dir", type=str, required=True,
                        help="–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏")
    parser.add_argument("--output", type=str, default="report.md",
                        help="–í–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –∑–≤—ñ—Ç—É")

    args = parser.parse_args()

    generate_report(args.artifacts_dir, args.output)

